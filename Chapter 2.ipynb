{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e2442fa-aee9-4e1e-9c5b-05e816197824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fffcfa0-65e6-4186-a69f-9a333633c95c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.4.0\n",
      "Is MPS (Metal Performance Shader) built? True\n",
      "Is MPS available? True\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Check PyTorch has access to MPS (Metal Performance Shader, Apple's GPU architecture)\n",
    "print(f\"Is MPS (Metal Performance Shader) built? {torch.backends.mps.is_built()}\")\n",
    "print(f\"Is MPS available? {torch.backends.mps.is_available()}\")\n",
    "\n",
    "# Set the device      \n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485063d5-9662-4673-af67-326d2fd8358d",
   "metadata": {},
   "source": [
    "### Loading the textbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d858a9fa-4ebc-4e35-b708-5ed1b4240efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so i\n"
     ]
    }
   ],
   "source": [
    "with open(\"the-verdict.txt\",\"r\", encoding = \"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "print(raw_text[:90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "681e2dbd-3b17-464b-abc0-071fd305333a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', ' ', ',', ' ', 'world.', ' ', 'Is', ' ', 'this', ' ', '--', ' ', 'a', ' ', 'test?']\n"
     ]
    }
   ],
   "source": [
    "text = \"hello , world. Is this -- a test?\"\n",
    "result = re.split(r'(\\s)',text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b748755-2422-4f91-8a02-d2b81c4b6612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', ',', 'world', '.', 'Is', 'this', '--', 'a', 'test', '?']\n"
     ]
    }
   ],
   "source": [
    "text = \"hello , world. Is this -- a test?\"\n",
    "result = re.split(r'([,.:;?_!\"()\\']|--|\\s)',text)\n",
    "result = [item.strip() for item in result if item.strip()]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17291ac5-8c7e-4e3a-aeb7-365929860933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4690 20479\n"
     ]
    }
   ],
   "source": [
    "preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)',raw_text)\n",
    "preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "print(len(preprocessed), len(raw_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0fcd28-0e6f-4aa4-99b1-1442f0eb555e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preprocessed[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95489c76-9d6b-4b9c-a224-994a2fbd7aee",
   "metadata": {},
   "source": [
    "### Creating Vocabulary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c70957f-b3f6-449c-9a71-e0be07399538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1130\n"
     ]
    }
   ],
   "source": [
    "all_words = sorted(list(set(preprocessed)))\n",
    "vocab_size = len(all_words)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb93584-2bda-4f88-970d-060752513fda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3ca807-d29e-4e89-99de-cb7defde69b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vocab = {token:integer for integer, token in enumerate(all_words)}\n",
    "for i, item in enumerate(vocab.items()):\n",
    "    print(item)\n",
    "    if i>50:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a8ebe6-1f2e-4afa-a5a7-1d099e52b3f0",
   "metadata": {},
   "source": [
    "### Simple Tokenizer V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b14935b-5e0e-4f78-9bba-00a8c4036b67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55edeaa2-fd8b-460f-877f-101d6af44c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a class\n",
    "class SimpleTokenizerV1:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i:s for s,i in vocab.items()}\n",
    "\n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)',text)\n",
    "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "\n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cff2b04-84a8-4fc8-afa4-aa462b76278b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[56, 2, 850, 988, 602, 533, 746, 5, 1126, 596]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizerV1(vocab)\n",
    "text = \"It's the last he painted, you know\"\n",
    "tokenizer.encode(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43975941-6eb4-444c-967a-6d9eab600939",
   "metadata": {},
   "source": [
    "### Simple Tokenizer V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62f96a84-ccaa-493e-99fe-c8c47bf84cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1132\n"
     ]
    }
   ],
   "source": [
    "all_tokens = sorted(list(set(preprocessed)))\n",
    "all_tokens.extend([\"<|endoftext|>\",\"<|unk|>\"])\n",
    "vocab = {token:integer for integer, token in enumerate(all_tokens)}\n",
    "print(len(vocab.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88007b76-a757-4282-b5b2-61619a2a29d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizerV2:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i:s for s,i in vocab.items()}\n",
    "\n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)',text)\n",
    "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "        preprocessed = [item if item in self.str_to_int else \"<|unk|>\" for item in preprocessed]\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dcb430e5-b56b-4547-ab3f-1154192a5c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello, do you like tea? We just got a cat <|endoftext|> In the sunlit terraces of the palace\n"
     ]
    }
   ],
   "source": [
    "text1 = \"hello, do you like tea? We just got a cat\"\n",
    "text2 = \"In the sunlit terraces of the palace\"\n",
    "text = \" <|endoftext|> \".join((text1,text2))\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74e913d6-79cc-421c-870b-40f14cc33e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = SimpleTokenizerV2(vocab)\n",
    "ids = tokenizer.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e49b2d-985b-477c-92ee-6616f868fb82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d3800e6-7c1a-46e9-bb6c-8945dfdbc062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|unk|>, do you like tea? We just got a <|unk|> <|endoftext|> In the sunlit terraces of the <|unk|>'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5595501-4f32-43ab-8392-4906d96c506a",
   "metadata": {},
   "source": [
    "### Byte Pair Encoding\n",
    "This is how the GPT models were tokenised. We didnt use the <|unk|> keyword for the unknown words, but split them using the \n",
    "byte pair encoding. We use tiktoken to do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b20cd1f4-6d6b-469e-85e3-e72d48bc0f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiktoken version: 0.7.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "import tiktoken\n",
    "print(\"tiktoken version:\", version(\"tiktoken\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6efb89e-6a05-4395-82d0-6d9a6e81fe2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0029a3ab-4f8a-478a-af1c-7c047a8ce176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31373, 11, 466, 345, 588, 8887, 393, 7532, 11913, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 558, 3160, 257, 9234, 3706, 24568, 10115]\n"
     ]
    }
   ],
   "source": [
    "text = \"hello, do you like tea or protein powder? <|endoftext|> In the sunlit terrace lives a monster named Cristiano\"\n",
    "ids = tokenizer.encode(text, allowed_special = {\"<|endoftext|>\"})\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "31a5752c-d167-46da-bbf8-62a7a96f612f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello, do you like tea or protein powder? <|endoftext|> In the sunlit terrace lives a monster named Cristiano'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strings = tokenizer.decode(ids)\n",
    "strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "797bdd77-bbea-4013-a976-2cf7c2951207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33901, 86, 343, 86, 466, 2238, 263, 220, 959]\n"
     ]
    }
   ],
   "source": [
    "text_unk = \"Akwirw doooer ier\"\n",
    "ids = tokenizer.encode(text_unk)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6592cce1-53f9-46f4-b8d2-3402b5108eda",
   "metadata": {},
   "source": [
    "### Data Sampling using Sliding Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fcb0aaf7-4e89-4c54-ab56-b55278983c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"the-verdict.txt\",\"r\", encoding = \"utf-8\") as f:\n",
    "    raw_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "44a5f992-e079-4380-a35c-d226017fe527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5145\n"
     ]
    }
   ],
   "source": [
    "enc_text = tokenizer.encode(raw_text)\n",
    "print(len(enc_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf34d8e1-10a4-47d2-ac68-27ff9295b841",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# removing first 50 as  the next is an interesting passage\n",
    "enc_sample = enc_text[50:]\n",
    "enc_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d915c8de-1c09-41f4-a7f0-d904548f6db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and established himself in a villa on the Riviera. (Though I rather thought it would have\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(enc_sample[:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0d8573af-ad66-4822-b3e2-953c11ae23a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [290, 4920, 2241, 287, 257, 4489, 64, 319, 262, 34686]\n",
      "y: [4920, 2241, 287, 257, 4489, 64, 319, 262, 34686, 41976]\n"
     ]
    }
   ],
   "source": [
    "context_size = 10\n",
    "x = enc_sample[:context_size]\n",
    "y = enc_sample[1:context_size+1]\n",
    "print(f\"x: {x}\")\n",
    "print(f\"y: {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d8e7490e-e18e-4c6b-bada-b36d1ad678b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of i is 1\n",
      "[290] ------> 4920\n",
      "Value of i is 2\n",
      "[290, 4920] ------> 2241\n",
      "Value of i is 3\n",
      "[290, 4920, 2241] ------> 287\n",
      "Value of i is 4\n",
      "[290, 4920, 2241, 287] ------> 257\n",
      "Value of i is 5\n",
      "[290, 4920, 2241, 287, 257] ------> 4489\n",
      "Value of i is 6\n",
      "[290, 4920, 2241, 287, 257, 4489] ------> 64\n",
      "Value of i is 7\n",
      "[290, 4920, 2241, 287, 257, 4489, 64] ------> 319\n",
      "Value of i is 8\n",
      "[290, 4920, 2241, 287, 257, 4489, 64, 319] ------> 262\n",
      "Value of i is 9\n",
      "[290, 4920, 2241, 287, 257, 4489, 64, 319, 262] ------> 34686\n",
      "Value of i is 10\n",
      "[290, 4920, 2241, 287, 257, 4489, 64, 319, 262, 34686] ------> 41976\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, context_size+1):\n",
    "    print(f\"Value of i is {i}\")\n",
    "    context = enc_sample[:i]\n",
    "    desired = enc_sample[i]\n",
    "    print(context, '------>', desired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bb939bac-87fe-419e-bdd4-fea5065775f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and ----------->  established\n",
      " and established ----------->  himself\n",
      " and established himself ----------->  in\n",
      " and established himself in ----------->  a\n",
      " and established himself in a ----------->  vill\n",
      " and established himself in a vill -----------> a\n",
      " and established himself in a villa ----------->  on\n",
      " and established himself in a villa on ----------->  the\n",
      " and established himself in a villa on the ----------->  Riv\n",
      " and established himself in a villa on the Riv -----------> iera\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, context_size+1):\n",
    "    context = enc_sample[:i]\n",
    "    desired = enc_sample[i]\n",
    "    print(tokenizer.decode(context), '----------->', tokenizer.decode([desired]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95208c4e-69fe-45d9-b32f-505a7b9c2958",
   "metadata": {},
   "source": [
    "### Creating dataset using Dataloader class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d11c5d80-9f6f-484c-b816-80d2d63351fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset , DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "51b4e3f7-220d-49da-8e84-b6733a4764fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "        token_ids = tokenizer.encode(txt)\n",
    "\n",
    "        for i in range(0, len(token_ids)-max_length, stride):\n",
    "            input_chunk = token_ids[i:i+max_length]\n",
    "            target_chunk = token_ids[i+1:i+max_length +1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "06750be6-e87c-4ccb-977d-5d4cb2185250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_v1(txt, batch_size = 4, max_length= 256, stride = 128, shuffle = True, drop_last = True):\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "    dataloader = DataLoader(dataset, batch_size= batch_size, shuffle = shuffle, drop_last = drop_last)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "99f14166-eb8f-4775-b7b1-ae1de0ea74e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257]])\n",
      "targets tensor([[  367,  2885,  1464,  1807],\n",
      "        [ 3619,   402,   271, 10899],\n",
      "        [ 2138,   257,  7026, 15632],\n",
      "        [  438,  2016,   257,   922]])\n"
     ]
    }
   ],
   "source": [
    "dataloader = create_dataloader_v1(raw_text, batch_size = 4, max_length = 4, stride = 4, shuffle = False)\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "print(\"Inputs\", inputs)\n",
    "print(\"targets\", targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "84eac14e-859a-46e2-be55-deb01c952372",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nth_batch(dataloader, n):\n",
    "    data_iter = iter(dataloader)\n",
    "    for _ in range(n):\n",
    "        batch = next(data_iter)\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2255f382-ad6e-46cf-bf68-812b16df1cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 12th batch input-output pair is:\n",
      "[tensor([[  996,   484,   547, 12548],\n",
      "        [  287,   281, 13079,   410],\n",
      "        [12523,   286, 22353,    13],\n",
      "        [  843,   340,   373,   407]]), tensor([[  484,   547, 12548,   287],\n",
      "        [  281, 13079,   410, 12523],\n",
      "        [  286, 22353,    13,   843],\n",
      "        [  340,   373,   407,   691]])]\n"
     ]
    }
   ],
   "source": [
    "n = 12\n",
    "nth_batch = get_nth_batch(dataloader, n)\n",
    "print(f\"The {n}th batch input-output pair is:\")\n",
    "print(nth_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6837ea3d-0734-4ed2-baa9-a2821a3a7fbe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Creating Token Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a6596f81-3669-4c72-8c10-1bdd2e9ea44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 5\n",
    "output_dim = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "13b1a343-8b5d-4229-9d8d-7a52387cb992",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "embedding_layer= torch.nn.Embedding(vocab_size, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ac658324-048b-4fe2-b306-f929d70d0c13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(5, 4)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8593a814-1dd6-4b0c-9914-a8af9e6ba947",
   "metadata": {},
   "source": [
    "This is basically making every word in the vocab into embeddings with output dim. So , the word at [0]th index can be represented by the numbers in the 3 Dimension space. Embedding layer is essentially a lookup ooperation that retrieves the row from the embedding layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "94468e56-4f56-4888-be9c-218995b4c07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.3374, -0.1778, -0.3035, -0.5880],\n",
      "        [ 1.5810,  1.3010,  1.2753, -0.2010],\n",
      "        [-0.1606, -0.4015,  0.6957, -1.8061],\n",
      "        [-1.1589,  0.3255, -0.6315, -2.8400],\n",
      "        [-0.7849, -1.4096, -0.4076,  0.7953]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "aa929bce-1275-440d-b719-2eccaa230cde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.4921,  0.2942, -0.1224, -0.4060],\n",
       "        [-0.6279, -0.0181,  1.1974,  0.0449],\n",
       "        [ 1.5480,  0.9281, -0.6564,  1.7713],\n",
       "        [-1.6067, -0.8521,  0.6658,  0.2453],\n",
       "        [ 0.7206, -0.2908,  1.4274,  0.4548],\n",
       "        [ 1.1140,  0.1213,  1.3954, -0.0235],\n",
       "        [-0.5937,  0.0789, -0.2475,  1.3596],\n",
       "        [-1.6196, -0.2544, -0.0432,  1.6211]], requires_grad=True)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = torch.tensor([1,2,3,4,5,6,7,8])\n",
    "embeddings = torch.nn.Embedding(len(indices), 4)\n",
    "embeddings.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "54f62bcd-c4bc-4133-aef1-c7f5be2df0e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4921,  0.2942, -0.1224, -0.4060], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.weight[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032b983d-6803-4e70-a625-046c4b1aa82a",
   "metadata": {},
   "source": [
    "### Encoding Word Positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b797bf37-d303-4419-9076-741a834c4295",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dim = 256\n",
    "vocab_size = 50257\n",
    "# The embedding layer will be of vocab_size x output_dim\n",
    "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "733409a5-a0b5-4c76-ad1d-f2aec71bce58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.4384, -0.6734, -0.5318,  ..., -1.6842,  0.0568, -1.7278],\n",
       "        [-1.8346,  0.2576, -1.6789,  ...,  0.1348, -1.0571,  1.2703],\n",
       "        [-0.5268,  1.3099,  0.5383,  ...,  0.0892,  0.2141, -1.4680],\n",
       "        ...,\n",
       "        [ 1.1078, -0.1039,  1.0237,  ...,  0.4691, -0.0714,  1.6100],\n",
       "        [ 1.8363,  0.3762, -0.9555,  ...,  0.7549, -1.0260, -0.2873],\n",
       "        [-0.2544, -0.3655,  0.8160,  ...,  0.0540, -0.6048, -0.2044]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(token_embedding_layer.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "90335ba7-ccfb-435b-8336-e147ad81c003",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 4\n",
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=8, max_length=max_length,\n",
    "    stride=max_length, shuffle=False\n",
    ")\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b858698c-a861-4902-af2c-b3cb39c60741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens IDs:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "Target/Output IDs: \n",
      " tensor([[  367,  2885,  1464,  1807],\n",
      "        [ 3619,   402,   271, 10899],\n",
      "        [ 2138,   257,  7026, 15632],\n",
      "        [  438,  2016,   257,   922],\n",
      "        [ 5891,  1576,   438,   568],\n",
      "        [  340,   373,   645,  1049],\n",
      "        [ 5975,   284,   502,   284],\n",
      "        [ 3285,   326,    11,   287]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Tokens IDs:\\n\", inputs)\n",
    "print(\"Target/Output IDs: \\n\", targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bc0119-edf0-40ed-ad43-eb1ee770b2bd",
   "metadata": {},
   "source": [
    "Each token is embedded into a 256 dimension layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "37f9ad90-53bd-49c9-9af1-c976d2d5eed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "token_embeddings = token_embedding_layer(inputs)\n",
    "# We get a tensor of 8 matrices, each with 4 rows and 256 columns\n",
    "# i.e 8 text samples with 4 Tokens each.\n",
    "# Ex- [['we','are','going','there'],\n",
    "#      ['but','who','are','you'],\n",
    "#      ['is','their','a','football'],\n",
    "#      ['yessir','player','best','Cristiano'],\n",
    "\n",
    "print((token_embeddings.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf71e15d-9d48-4c9b-ac22-df140bcc8b1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "token_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388228fe-0c15-45d4-83c9-65dbdf9ced98",
   "metadata": {},
   "source": [
    "GPT-2 uses absolute position embeddings, so we just create another embedding layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "aa9214bf-17dc-40d3-b9af-adbeca3f4e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = max_length\n",
    "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "58076564-78f8-453b-b547-dbb33228f1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 256])\n"
     ]
    }
   ],
   "source": [
    "pos_embeddings = pos_embedding_layer(torch.arange(max_length))\n",
    "print(pos_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9ff9f72a-4e9e-4987-a7b0-4bd27c666d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2963,  1.1832,  1.5249,  ...,  1.3411, -0.5805,  0.4113],\n",
       "        [ 1.6007,  2.9084,  1.3047,  ...,  0.4405, -0.2261, -0.2018],\n",
       "        [ 0.8951, -0.1793,  1.0270,  ..., -1.5806, -0.9663,  0.4029],\n",
       "        [ 0.6337, -0.5549, -1.3543,  ..., -1.2076, -1.6081,  1.2127]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cbe5832c-32c1-40d8-a61d-97c12ec759d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "input_embeddings = token_embeddings + pos_embeddings\n",
    "print(input_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9027af68-9be2-4bd0-a29f-69fe4600dab2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
