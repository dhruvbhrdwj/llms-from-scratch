{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a87839a-6dcb-46c0-a9b1-f11ed17a12ea",
   "metadata": {},
   "source": [
    "## Implementing Byte Pair Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9a0c8346-ad6f-4d24-b803-0676a5754b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTHONIOENCODING\"] = \"utf-8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6dce4586-ab75-4d37-8a28-5ad49297fd07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "नमस्ते\n"
     ]
    }
   ],
   "source": [
    "print(\"नमस्ते\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72641c49-493b-4e15-a9ac-dc40579d9ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every breath you take\n"
     ]
    }
   ],
   "source": [
    "text = 'Every breath you take'\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cb3fb48-6c7e-4111-9cad-03642acf9e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bytearray(b'Every breath you take')\n"
     ]
    }
   ],
   "source": [
    "byte_ary = bytearray(text, \"utf-8\")\n",
    "print(byte_ary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4988228-62d4-4223-8b84-4b1598083ca6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[69,\n",
       " 118,\n",
       " 101,\n",
       " 114,\n",
       " 121,\n",
       " 32,\n",
       " 98,\n",
       " 114,\n",
       " 101,\n",
       " 97,\n",
       " 116,\n",
       " 104,\n",
       " 32,\n",
       " 121,\n",
       " 111,\n",
       " 117,\n",
       " 32,\n",
       " 116,\n",
       " 97,\n",
       " 107,\n",
       " 101]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = list(byte_ary)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fae9fac2-615e-40d9-a107-545ec6156245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6109, 8033, 345, 1011]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "gpt2_tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "gpt2_tokenizer.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af2dd74c-78e8-4a69-835a-627b3c945282",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: !\n",
      "1: \"\n",
      "2: #\n",
      "3: $\n",
      "4: %\n",
      "5: &\n",
      "6: '\n",
      "7: (\n",
      "8: )\n",
      "9: *\n",
      "10: +\n",
      "11: ,\n",
      "12: -\n",
      "13: .\n",
      "14: /\n",
      "15: 0\n",
      "16: 1\n",
      "17: 2\n",
      "18: 3\n",
      "19: 4\n",
      "20: 5\n",
      "21: 6\n",
      "22: 7\n",
      "23: 8\n",
      "24: 9\n",
      "25: :\n",
      "26: ;\n",
      "27: <\n",
      "28: =\n",
      "29: >\n",
      "30: ?\n",
      "31: @\n",
      "32: A\n",
      "33: B\n",
      "34: C\n",
      "35: D\n",
      "36: E\n",
      "37: F\n",
      "38: G\n",
      "39: H\n",
      "40: I\n",
      "41: J\n",
      "42: K\n",
      "43: L\n",
      "44: M\n",
      "45: N\n",
      "46: O\n",
      "47: P\n",
      "48: Q\n",
      "49: R\n",
      "50: S\n",
      "51: T\n",
      "52: U\n",
      "53: V\n",
      "54: W\n",
      "55: X\n",
      "56: Y\n",
      "57: Z\n",
      "58: [\n",
      "59: \\\n",
      "60: ]\n",
      "61: ^\n",
      "62: _\n",
      "63: `\n",
      "64: a\n",
      "65: b\n",
      "66: c\n",
      "67: d\n",
      "68: e\n",
      "69: f\n",
      "70: g\n",
      "71: h\n",
      "72: i\n",
      "73: j\n",
      "74: k\n",
      "75: l\n",
      "76: m\n",
      "77: n\n",
      "78: o\n",
      "79: p\n",
      "80: q\n",
      "81: r\n",
      "82: s\n",
      "83: t\n",
      "84: u\n",
      "85: v\n",
      "86: w\n",
      "87: x\n",
      "88: y\n",
      "89: z\n",
      "90: {\n",
      "91: |\n",
      "92: }\n",
      "93: ~\n",
      "94: �\n",
      "95: �\n",
      "96: �\n",
      "97: �\n",
      "98: �\n",
      "99: �\n",
      "100: �\n",
      "101: �\n",
      "102: �\n",
      "103: �\n",
      "104: �\n",
      "105: �\n",
      "106: �\n",
      "107: �\n",
      "108: �\n",
      "109: �\n",
      "110: �\n",
      "111: �\n",
      "112: �\n",
      "113: �\n",
      "114: �\n",
      "115: �\n",
      "116: �\n",
      "117: �\n",
      "118: �\n",
      "119: �\n",
      "120: �\n",
      "121: �\n",
      "122: �\n",
      "123: �\n",
      "124: �\n",
      "125: �\n",
      "126: �\n",
      "127: �\n",
      "128: �\n",
      "129: �\n",
      "130: �\n",
      "131: �\n",
      "132: �\n",
      "133: �\n",
      "134: �\n",
      "135: �\n",
      "136: �\n",
      "137: �\n",
      "138: �\n",
      "139: �\n",
      "140: �\n",
      "141: �\n",
      "142: �\n",
      "143: �\n",
      "144: �\n",
      "145: �\n",
      "146: �\n",
      "147: �\n",
      "148: �\n",
      "149: �\n",
      "150: �\n",
      "151: �\n",
      "152: �\n",
      "153: �\n",
      "154: �\n",
      "155: �\n",
      "156: �\n",
      "157: �\n",
      "158: �\n",
      "159: �\n",
      "160: �\n",
      "161: �\n",
      "162: �\n",
      "163: �\n",
      "164: �\n",
      "165: �\n",
      "166: �\n",
      "167: �\n",
      "168: �\n",
      "169: �\n",
      "170: �\n",
      "171: �\n",
      "172: �\n",
      "173: �\n",
      "174: �\n",
      "175: �\n",
      "176: �\n",
      "177: �\n",
      "178: �\n",
      "179: �\n",
      "180: �\n",
      "181: �\n",
      "182: �\n",
      "183: �\n",
      "184: �\n",
      "185: �\n",
      "186: �\n",
      "187: �\n",
      "188: \u0000\n",
      "189: \u0001\n",
      "190: \u0002\n",
      "191: \u0003\n",
      "192: \u0004\n",
      "193: \u0005\n",
      "194: \u0006\n",
      "195: \u0007\n",
      "196:\n",
      "197: \t\n",
      "198: \n",
      "\n",
      "199: \u000b",
      "\n",
      "200: \f",
      "\n",
      "201: \n",
      "202: \u000e\n",
      "203: \u000f\n",
      "204: \u0010\n",
      "205: \u0011\n",
      "206: \u0012\n",
      "207: \u0013\n",
      "208: \u0014\n",
      "209: \u0015\n",
      "210: \u0016\n",
      "211: \u0017\n",
      "212: \u0018\n",
      "213: \u0019\n",
      "214: \u001a\n",
      "215: \u001b\n",
      "216: \u001c",
      "\n",
      "217: \u001d",
      "\n",
      "218: \u001e",
      "\n",
      "219: \u001f\n",
      "220:  \n",
      "221: \n",
      "222: �\n",
      "223: �\n",
      "224: �\n",
      "225: �\n",
      "226: �\n",
      "227: �\n",
      "228: �\n",
      "229: �\n",
      "230: �\n",
      "231: �\n",
      "232: �\n",
      "233: �\n",
      "234: �\n",
      "235: �\n",
      "236: �\n",
      "237: �\n",
      "238: �\n",
      "239: �\n",
      "240: �\n",
      "241: �\n",
      "242: �\n",
      "243: �\n",
      "244: �\n",
      "245: �\n",
      "246: �\n",
      "247: �\n",
      "248: �\n",
      "249: �\n",
      "250: �\n",
      "251: �\n",
      "252: �\n",
      "253: �\n",
      "254: �\n",
      "255: �\n",
      "256:  t\n",
      "257:  a\n",
      "258: he\n",
      "259: in\n",
      "260: re\n",
      "261: on\n",
      "262:  the\n",
      "263: er\n",
      "264:  s\n",
      "265: at\n",
      "266:  w\n",
      "267:  o\n",
      "268: en\n",
      "269:  c\n",
      "270: it\n",
      "271: is\n",
      "272: an\n",
      "273: or\n",
      "274: es\n",
      "275:  b\n",
      "276: ed\n",
      "277:  f\n",
      "278: ing\n",
      "279:  p\n",
      "280: ou\n",
      "281:  an\n",
      "282: al\n",
      "283: ar\n",
      "284:  to\n",
      "285:  m\n",
      "286:  of\n",
      "287:  in\n",
      "288:  d\n",
      "289:  h\n",
      "290:  and\n",
      "291: ic\n",
      "292: as\n",
      "293: le\n",
      "294:  th\n",
      "295: ion\n",
      "296: om\n",
      "297: ll\n",
      "298: ent\n",
      "299:  n\n"
     ]
    }
   ],
   "source": [
    "for i in range(300):\n",
    "    decoded = gpt2_tokenizer.decode([i])\n",
    "    print(f\"{i}: {decoded}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5be788b-1882-46ac-9f47-385e9d02fdd6",
   "metadata": {},
   "source": [
    "### Algorithm\n",
    "- We go step by step, find the frequency of the most repeated pairs\n",
    "- We assign an ID to them\n",
    "- We do the same again, find the next most common repeated pairs\n",
    "- Assign IDs to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6c6fb5c8-552c-4a4f-93c7-d0fbb7e5b1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file_path = 'hindi_sample.txt'\n",
    "f = open(text_file_path, \"r\")\n",
    "sample = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320cc394-ecd0-4d84-8235-ff013c1dc10a",
   "metadata": {},
   "source": [
    "### Building a Hindi Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ab592645-3b15-4aa1-bf8a-f187e94e41a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Remove unnecessary whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # Remove special characters but keep Hindi characters\n",
    "    text = re.sub(r'[^\\u0900-\\u097F\\s]', '', text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "afd2c203-3740-4d9b-a943-3aa667247414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'गोपी प्रेम हनुमान प्रसाद पोद्दार द्वारा लिखी गई एक अद्वितीय धार्मिक और भक्ति साहित्य की पुस्तक है। यह पुस्तक भगवान श्रीकृष्ण और गोपियों के बीच के प्रेम और भक्ति के अद्वितीय और अनमोल संबंधों को सजीव रूप में प्रस्तुत करती है। गोपियों का भगवान कृष्ण के प्रति असीम प्रेम भक्ति और समर्पण इस पुस्तक का मुख्य विषय है।हनुमान प्रसाद पोद्दार ने इस पुस्तक में गोपियों की निश्छल भक्ति उनकी तन्मयता और भगवान कृष्ण के प्रति उनके प्रेम का बहुत ही सुंदर और मार्मिक वर्णन किया है। पुस्तक में वर्णित भावनाएँ और भक्ति रस पाठकों को गहरे आध्यात्मिक और भावनात्मक स्तर पर छू जाती हैं। गोपी प्रेम न केवल भक्तों को भगवान श्रीकृष्ण की भक्ति की महिमा से अवगत कराती है बल्कि उन्हें भक्ति मार्ग पर चलने के लिए प्रेरित भी करती है। यह पुस्तक भगवान श्रीकृष्ण के प्रति गोपियों की अनन्य भक्ति को जीवंत करती है और पाठकों को भक्ति और प्रेम के वास्तविक अर्थ से अवगत कराती है। गोपी प्रेम हर उस व्यक्ति के लिए एक अनमोल धरोहर है जो भगवान श्रीकृष्ण के प्रति गहरी भक्ति और प्रेम को समझना और अनुभव करना चाहता है।'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_preprocessed = preprocess_text(sample)\n",
    "sample_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cc39f370-4fc5-4ef2-96f5-10fc1f279d9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "processed_text = []\n",
    "for i , char in enumerate(sample_preprocessed[:50]):\n",
    "    if char == \" \" and i!=0:\n",
    "        processed_text.append(\"</w>\")\n",
    "    if char != \" \":\n",
    "        processed_text.append(char)\n",
    "processed_text = \"\".join(processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "22ad231a-cb70-4d7b-b78d-d0c6aea67699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'गोपी</w>प्रेम</w>हनुमान</w>प्रसाद</w>पोद्दार</w>द्वारा</w>लिखी</w>गई</w>एक'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e7784a8c-93fa-48c0-9744-6e8969c3edad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\x00',\n",
       " '\\x01',\n",
       " '\\x02',\n",
       " '\\x03',\n",
       " '\\x04',\n",
       " '\\x05',\n",
       " '\\x06',\n",
       " '\\x07',\n",
       " '\\x08',\n",
       " '\\t',\n",
       " '\\n',\n",
       " '\\x0b',\n",
       " '\\x0c',\n",
       " '\\r',\n",
       " '\\x0e',\n",
       " '\\x0f',\n",
       " '\\x10',\n",
       " '\\x11',\n",
       " '\\x12',\n",
       " '\\x13',\n",
       " '\\x14',\n",
       " '\\x15',\n",
       " '\\x16',\n",
       " '\\x17',\n",
       " '\\x18',\n",
       " '\\x19',\n",
       " '\\x1a',\n",
       " '\\x1b',\n",
       " '\\x1c',\n",
       " '\\x1d',\n",
       " '\\x1e',\n",
       " '\\x1f',\n",
       " ' ',\n",
       " '!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'V',\n",
       " 'W',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'Z',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~',\n",
       " '\\x7f',\n",
       " '\\x80',\n",
       " '\\x81',\n",
       " '\\x82',\n",
       " '\\x83',\n",
       " '\\x84',\n",
       " '\\x85',\n",
       " '\\x86',\n",
       " '\\x87',\n",
       " '\\x88',\n",
       " '\\x89',\n",
       " '\\x8a',\n",
       " '\\x8b',\n",
       " '\\x8c',\n",
       " '\\x8d',\n",
       " '\\x8e',\n",
       " '\\x8f',\n",
       " '\\x90',\n",
       " '\\x91',\n",
       " '\\x92',\n",
       " '\\x93',\n",
       " '\\x94',\n",
       " '\\x95',\n",
       " '\\x96',\n",
       " '\\x97',\n",
       " '\\x98',\n",
       " '\\x99',\n",
       " '\\x9a',\n",
       " '\\x9b',\n",
       " '\\x9c',\n",
       " '\\x9d',\n",
       " '\\x9e',\n",
       " '\\x9f',\n",
       " '\\xa0',\n",
       " '¡',\n",
       " '¢',\n",
       " '£',\n",
       " '¤',\n",
       " '¥',\n",
       " '¦',\n",
       " '§',\n",
       " '¨',\n",
       " '©',\n",
       " 'ª',\n",
       " '«',\n",
       " '¬',\n",
       " '\\xad',\n",
       " '®',\n",
       " '¯',\n",
       " '°',\n",
       " '±',\n",
       " '²',\n",
       " '³',\n",
       " '´',\n",
       " 'µ',\n",
       " '¶',\n",
       " '·',\n",
       " '¸',\n",
       " '¹',\n",
       " 'º',\n",
       " '»',\n",
       " '¼',\n",
       " '½',\n",
       " '¾',\n",
       " '¿',\n",
       " 'À',\n",
       " 'Á',\n",
       " 'Â',\n",
       " 'Ã',\n",
       " 'Ä',\n",
       " 'Å',\n",
       " 'Æ',\n",
       " 'Ç',\n",
       " 'È',\n",
       " 'É',\n",
       " 'Ê',\n",
       " 'Ë',\n",
       " 'Ì',\n",
       " 'Í',\n",
       " 'Î',\n",
       " 'Ï',\n",
       " 'Ð',\n",
       " 'Ñ',\n",
       " 'Ò',\n",
       " 'Ó',\n",
       " 'Ô',\n",
       " 'Õ',\n",
       " 'Ö',\n",
       " '×',\n",
       " 'Ø',\n",
       " 'Ù',\n",
       " 'Ú',\n",
       " 'Û',\n",
       " 'Ü',\n",
       " 'Ý',\n",
       " 'Þ',\n",
       " 'ß',\n",
       " 'à',\n",
       " 'á',\n",
       " 'â',\n",
       " 'ã',\n",
       " 'ä',\n",
       " 'å',\n",
       " 'æ',\n",
       " 'ç',\n",
       " 'è',\n",
       " 'é',\n",
       " 'ê',\n",
       " 'ë',\n",
       " 'ì',\n",
       " 'í',\n",
       " 'î',\n",
       " 'ï',\n",
       " 'ð',\n",
       " 'ñ',\n",
       " 'ò',\n",
       " 'ó',\n",
       " 'ô',\n",
       " 'õ',\n",
       " 'ö',\n",
       " '÷',\n",
       " 'ø',\n",
       " 'ù',\n",
       " 'ú',\n",
       " 'û',\n",
       " 'ü',\n",
       " 'ý',\n",
       " 'þ',\n",
       " 'ÿ']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_chars = [chr(i) for i in range(256)]\n",
    "unique_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff25c442-7952-456c-8928-883d3d90d0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPETokenizerHindi:\n",
    "    def __init__(self):\n",
    "        self.vocab = {}\n",
    "        self.token_to_id = {}\n",
    "        self.id_to_token = {}\n",
    "        self.bpe_merges = 0\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        # Remove special characters but keep Hindi characters\n",
    "        text = re.sub(r'[^\\u0900-\\u097F\\s]', '', text)\n",
    "        return text.strip()\n",
    "\n",
    "    def train(self, text):\n",
    "        ## Training Loop\n",
    "        processed_text = []\n",
    "        for i , char in enumerate(text):\n",
    "            if char == \" \" and i!=0:\n",
    "                processed_text.append(\"</w>\")\n",
    "            if char != \" \":\n",
    "                processed_text.append(char)\n",
    "        processed_text = \"\".join(processed_text)\n",
    "            \n",
    "        unique_chars = [chr(i) for i in range(256)]\n",
    "\n",
    "        if \"</w>\" not in unique_chars:\n",
    "            unique_chars.append(\"</w>\")\n",
    "\n",
    "        # Creating Vocab\n",
    "        self.vocab = {i:char for i, char in enumerate(unique_chars)}\n",
    "        self.inverse_vocab = {char: i for i, char in self.vocab.items()}\n",
    "\n",
    "        tokens_ids = [self.inverse_vocab[char] for char in processed_text]\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903fbbbc-8179-4dac-8fae-05a4606f422b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
